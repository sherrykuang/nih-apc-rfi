{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2c25d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "\n",
    "responses_csv = \"nih.apc.csv\"\n",
    "\n",
    "df = pd.read_csv(responses_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ebe0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract references and links from comments ###\n",
    "\n",
    "def extract_links(text):\n",
    "    \n",
    "    # define url pattern as starting with http OR https \n",
    "    url_pattern = (r'(https?://[^\\s]+)' + r'(http://[^\\s]+)')\n",
    "\n",
    "    # define web address as any letter preceding and following a period, e.g., openapc.net\n",
    "    web_address = r'([a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'\n",
    "\n",
    "    doi_pattern = r'(doi:\\s*10\\.\\d{4,9}/[-._;()/:A-Z0-9]+)'\n",
    "\n",
    "    return re.findall(url_pattern, text) + re.findall(doi_pattern, text) + re.findall(web_address, text)\n",
    "\n",
    "def extract_citations(text):\n",
    "    res = []\n",
    "\n",
    "    patterns_list = [\n",
    "\n",
    "        r'\\([^()]+?,\\s*\\d{4}\\)',  # Author, Year\n",
    "        r'[A-Z][a-zA-Z]+ et al\\.', # Author et al\n",
    "        r'\\(([^()]+? et al., \\s*\\d{4})\\)',  # (Author et al., Year)\n",
    "        r'[A-Z][a-zA-Z]+ et al\\. (\\d{4})',  # Author et al. (Year)\n",
    "        r'[A-Z][a-zA-Z]+ and [A-Z][a-zA-Z]+ \\((\\d{4})\\)',  # Author and Author (Year)\n",
    "        r'[A-Z][a-zA-Z]+ & [A-Z][a-zA-Z]+ \\((\\d{4})\\)',  # Author & Author (Year)\n",
    "        r'([A-Z][a-zA-Z]+ et al\\. \\(([^()]+?,\\s*\\d{4})\\))',  # Author et al. (Author, 2011)\n",
    "\n",
    "    ]\n",
    "    for pattern in patterns_list:\n",
    "        matches = re.findall(pattern, text)\n",
    "        for match in matches:\n",
    "            if isinstance(match, tuple):\n",
    "                res.append(match[0])\n",
    "            else:\n",
    "                res.append(match)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d2412f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Science, 2011)', 'Ginther et al.', 'Ginther et al. (Science, 2011)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check individual cases ###\n",
    "\n",
    "extract_citations(df['Comment'][139])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28ab375a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Record.ID                                           Citation  \\\n",
      "0           6                                                 []   \n",
      "1          16                              [(Coalition S, 2022)]   \n",
      "2          24                                                 []   \n",
      "3          42                                                 []   \n",
      "4          52                                                 []   \n",
      "5          57                                                 []   \n",
      "6          78                                                 []   \n",
      "7         115                                                 []   \n",
      "8         140  [(Science, 2011), Ginther et al., Ginther et a...   \n",
      "9         144                                                 []   \n",
      "10        159                                                 []   \n",
      "11        166                                                 []   \n",
      "12        169                               [(from Jan 1, 2025)]   \n",
      "13        193                                                 []   \n",
      "14        199                                                 []   \n",
      "15        203                                                 []   \n",
      "16        218                                                 []   \n",
      "17        222                                                 []   \n",
      "18        229                                                 []   \n",
      "19        243                                                 []   \n",
      "\n",
      "                                                Links  \n",
      "0   [pmc.ncbi.nlm.nih.gov, scholarlykitchen.sspnet...  \n",
      "1                                                  []  \n",
      "2                                [acsopenscience.org]  \n",
      "3                               [www.theguardian.com]  \n",
      "4   [openapc.net, mendelity.com, arxiv.org, relx.c...  \n",
      "5   [f1000research.com, www.frontiersin.org, www.f...  \n",
      "6                       [doi.org, arxiv.org, doi.org]  \n",
      "7                                   [www.amecera.org]  \n",
      "8                                                  []  \n",
      "9    [onlinelibrary.wiley.com, www.sciencedirect.com]  \n",
      "10               [link.springer.com, jamanetwork.com]  \n",
      "11  [www.arcadiascience.com, research.arcadiascien...  \n",
      "12                                                 []  \n",
      "13             [www.nature.com, pmc.ncbi.nlm.nih.gov]  \n",
      "14                                         [not...It]  \n",
      "15                      [research.arcadiascience.com]  \n",
      "16  [www.nature.com, www.nature.com, www.nature.co...  \n",
      "17                            [jane.biosemantics.org]  \n",
      "18                               [www.deltathink.com]  \n",
      "19  [doi: 10.1158/1541-7786.MCR-22-0085., scisigna...  \n"
     ]
    }
   ],
   "source": [
    "### loop over all comments and extract citations and links to a list with their corresponding Record.ID ###\n",
    "\n",
    "citations_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    record_id = row['Record.ID']\n",
    "    comment = row['Comment']\n",
    "    citations = extract_citations(comment)\n",
    "    links = extract_links(comment)\n",
    "    if (not citations) and (not links):\n",
    "        continue\n",
    "    citations_data.append({'Record.ID': record_id, 'Citation': citations, 'Links': links})\n",
    "\n",
    "citations_df = pd.DataFrame(citations_data)\n",
    "print(citations_df.head(20))\n",
    "\n",
    "citations_df.to_csv('nih_apc_citations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ed77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### retrieve citations and links in-context with surrounding text ###\n",
    "def get_context(text, target, window=50):\n",
    "    contexts = []\n",
    "    for match in re.finditer(re.escape(target), text):\n",
    "        start = max(match.start() - window, 0)\n",
    "        end = min(match.end() + window, len(text))\n",
    "        context = text[start:end]\n",
    "        contexts.append(context)\n",
    "    return contexts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
